{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal de tres capas en Pytorch\n",
    "\n",
    "Los números utilizados para ejercicio se pueden descargar de:\n",
    "http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Los archivos descomprimidos deberán de colocarse en la carpeta /mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from time import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import json, matplotlib\n",
    "s = json.load( open(\"styles/bmh_matplotlibrc.json\") )\n",
    "matplotlib.rcParams.update(s)\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(11, 5)\n",
    "colores = [\"#348ABD\", \"#A60628\",\"#06A628\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interact_manual, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos\n",
    "\n",
    "Los datos a utilizar son imágenes de dígitos.  En su formato original, se leen dos vectores:\n",
    "* Los datos de **entrada** vienen en un vector 3D.\n",
    "  * Cada renglón corresponde a un ejemplar de entrenamiento.\n",
    "  * En cada renglón hay una matriz 2D con las intensidades de los pixels.\n",
    "* Las etiquetas (dígito correcto que representan) vienen en un vector de una dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de  3  dimensiones:  (60000, 28, 28)  tipo  <class 'numpy.uint8'>\n",
      "Vector de  1  dimensiones:  (60000,)  tipo  <class 'numpy.uint8'>\n",
      "Vector de  3  dimensiones:  (10000, 28, 28)  tipo  <class 'numpy.uint8'>\n",
      "Vector de  1  dimensiones:  (10000,)  tipo  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "from mnist.read import read, printFull\n",
    "\n",
    "filesDir = './mnist/'\n",
    "trainingSetFile = filesDir + 'train-images.idx3-ubyte'\n",
    "trainingSetLabelsFile = filesDir + 'train-labels.idx1-ubyte'\n",
    "testSetFile = filesDir + 't10k-images.idx3-ubyte'\n",
    "testSetLabelsFile = filesDir + 't10k-labels.idx1-ubyte'\n",
    "\n",
    "\n",
    "###     /\\ |__   __||  ____|| \\ | | / ____||_   _|/ __ \\ | \\ | |\n",
    "###    /  \\   | |   | |__   |  \\| || |       | | | |  | ||  \\| |\n",
    "###   / /\\ \\  | |   |  __|  | . ` || |       | | | |  | || . ` |\n",
    "###  / ____ \\ | |   | |____ | |\\  || |____  _| |_| |__| || |\\  |\n",
    "### /_/    \\_\\|_|   |______||_| \\_| \\_____||_____|\\____/ |_| \\_|\n",
    "### EN LAS SIQUIENTES DOS LINEAS SE LIMITA EL TAMAÑO DE LOS DATOS DE ENTRENAMIENTO,EN CASO\n",
    "### DE INCREMENTAR LA CANTIDAD EL CALCULO TOMA DRASTICAMENTE MAS TIEMPO EN EL CASO DE APROXIMACION DEL GRADIENTE,SE INCLUYE\n",
    "### IMPRESION DEL PROGRESO DEL METODO\n",
    "\n",
    "\n",
    "\n",
    "trainData = read(fileName=trainingSetFile).astype(np.float64)\n",
    "trainDataLabels = read(fileName=trainingSetLabelsFile).astype(np.float64)\n",
    "\n",
    "testData = read(fileName=testSetFile).astype(np.float64)\n",
    "testDataLabels = read(fileName=testSetLabelsFile).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist.plot\n",
    "from mnist.plot import muestraImagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f73adee5a14a5e8d978e5c0d871713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=29999, description='indice', max=59999), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(\n",
    "    indice = (0, len(trainData) - 1)\n",
    ")\n",
    "def muestraImagenEntrenamiento(indice):\n",
    "    muestraImagen(trainData, trainDataLabels, indice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder trabajar con la red neuronal, necesitaremos transformar esas entradas, de modo que los valores de las intensidades de los pixeles se encuentren en un solo renglón.  Las entradas a la red neuronal, deberán ser de la forma:\n",
    "\\begin{align}\n",
    "  X &= \\begin{bmatrix}\n",
    "       x_1^{(1)} ... x_n^{(1)}  \\\\\n",
    "       x_1^{(2)} ... x_n^{(2)}  \\\\\n",
    "       ...\\\\\n",
    "       x_1^{(m)} ... x_n^{(m)}\n",
    "      \\end{bmatrix}\n",
    "\\end{align}\n",
    "También necesitaremos que las etiquetas formen una matriz donde la única columna distinta de cero, sea la correspondiente al dígito correcto:\n",
    "\\begin{align}\n",
    "  Y &= \\begin{bmatrix}\n",
    "       0, ..., y_{label_0} = 1 , ... ,0 \\\\\n",
    "       ... \\\\\n",
    "       0, ..., y_{label_n} = 1 , ... ,0 \\\\\n",
    "      \\end{bmatrix}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = torch.FloatTensor([x_tensor])\n",
    "        self.y = torch.FloatTensor([y_tensor])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de  3  dimensiones:  (60000, 28, 28)  tipo  <class 'numpy.uint8'>\n",
      "Vector de  1  dimensiones:  (60000,)  tipo  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "## Define las matrices X y Y, como se muestra arriba\n",
    "## A partir de trainData y trainDataLabels\n",
    "## TIP: usar reshape\n",
    "def makeX(file_set):\n",
    "    data = read(file_set).astype(np.float64)\n",
    "    data = np.reshape(data,(len(data),-1)) #flattening image into vector\n",
    "    data = (data - data.mean())/data.std() #normalizing data\n",
    "    return data\n",
    "\n",
    "def makeY(file_labels):\n",
    "    data = read(file_labels).astype(np.float64)\n",
    "    return data\n",
    "\n",
    "x_train_numpy = makeX(\"mnist/train-images.idx3-ubyte\")\n",
    "y_train_numpy = makeY(\"mnist/train-labels.idx1-ubyte\")\n",
    "\n",
    "x_train_tensor = torch.FloatTensor(x_train_numpy)\n",
    "y_train_tensor = torch.FloatTensor(y_train_numpy)\n",
    "\n",
    "#train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "train_data = utils.TensorDataset(x_train_tensor,y_train_tensor)\n",
    "XY_Train = utils.DataLoader(train_data, batch_size=128, shuffle=False) # create your dataloader\n",
    "\n",
    "#for i,batch in enumerate(XY_Train):\n",
    "#    print(i,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de  3  dimensiones:  (10000, 28, 28)  tipo  <class 'numpy.uint8'>\n",
      "Vector de  1  dimensiones:  (10000,)  tipo  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "## Repite lo mismo con los datos de entrenamiento\n",
    "XTest = makeX(\"mnist/t10k-images.idx3-ubyte\")\n",
    "YTest = makeY(\"mnist/t10k-labels.idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red con tres capas\n",
    "La red neuronal que se utilizará es una red neuronal de tres capas:\n",
    "* Entrada\n",
    "* Oculta\n",
    "* Salida\n",
    "La forma genérica de la red se ilustra a continuación.  Sólo que la red de este ejercicio tendrá más neuronas en cada capa.\n",
    "<img src=\"figuras/Red3Capas.png\"/>\n",
    "Para este ejercicio el número de neuronas será:\n",
    "* 785 + 1 (28x28 pixeles más la unidad de sesgo)\n",
    "* X + 1 unidades en la capa oculta donde X es elección del diseñador\n",
    "* 10 neuronas de salida (una por cada dígito)\n",
    "Por lo tanto, las dimensiones de las matrices de pesos son:\n",
    "* $\\Theta^{(0)} \\rightarrow (25 \\times 786)$\n",
    "* $\\Theta^{(1)} \\rightarrow (10 \\times 26)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Programa una clase RedNeuronal en PyTorch con la arquitectura anterior.\n",
    "\n",
    "class NN:\n",
    "    def __init__(self,input_size,hidden,output_size):\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.Linear(hidden,output_size),\n",
    "            nn.Softmax(dim=1),\n",
    "            nn.BatchNorm1d(output_size)\n",
    "          ).to(device)\n",
    "        self.losses = []\n",
    "        \n",
    "    def feedForward(self,X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def backPropagate(self,X,Y):\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        out = self.feedForward(X)\n",
    "        error = self.loss(out,Y)\n",
    "        error.backward()\n",
    "        return error\n",
    "        \n",
    "    def train(self,XY_DataLoader,NofE=100):\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "        self.optimizer = optim.Adagrad(self.model.parameters(), lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        for epoch in tqdm(range(NofE)):\n",
    "            for x_batch, y_batch in XY_DataLoader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                self.train_step(x_batch,y_batch)\n",
    "                #print(len(x_batch))\n",
    "    \n",
    "    def train_step(self,x,y):\n",
    "         # Sets model to TRAIN mode\n",
    "        self.model.train()\n",
    "        # Makes predictions\n",
    "        yhat = self.model(x)\n",
    "        # Computes loss\n",
    "        loss = self.loss(yhat,y.long())\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        # saves the loss\n",
    "        self.losses.append(loss.item())\n",
    "                \n",
    "    def test(self,test_X,test_Y):\n",
    "        tensor_X = Variable(torch.FloatTensor(test_X),requires_grad = True).to(device)\n",
    "        tensor_Y = Variable(torch.LongTensor(test_Y),requires_grad = False).to(device)\n",
    "        out = self.feedForward(tensor_X)\n",
    "        accT = out.argmax(dim=1)==tensor_Y\n",
    "        accT = torch.sum(accT)\n",
    "        acc = accT.data.numpy()/test_X.shape[0]\n",
    "        print(\"Acc:\",acc*100,\"%\")\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:01<01:47,  1.08s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:02<02:10,  1.33s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:04<02:04,  1.29s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:05<01:55,  1.20s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:06<01:47,  1.14s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:07<01:42,  1.09s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:08<01:38,  1.06s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:09<01:35,  1.04s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:10<01:33,  1.03s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:11<01:31,  1.02s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:12<01:30,  1.01s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:13<01:29,  1.02s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:14<01:28,  1.01s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:15<01:28,  1.03s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:16<01:34,  1.11s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:17<01:32,  1.10s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:18<01:31,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:19<01:27,  1.06s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:20<01:23,  1.04s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:21<01:20,  1.01s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:23<01:38,  1.25s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:25<01:46,  1.36s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:26<01:42,  1.33s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:27<01:47,  1.41s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:29<01:45,  1.41s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:30<01:36,  1.31s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:32<01:44,  1.43s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:33<01:36,  1.35s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:34<01:35,  1.35s/it]\u001b[A\n",
      " 30%|███       | 30/100 [00:36<01:42,  1.46s/it]\u001b[A\n",
      " 31%|███       | 31/100 [00:37<01:36,  1.40s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:39<01:43,  1.53s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:40<01:41,  1.51s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:42<01:33,  1.41s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:43<01:25,  1.32s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:44<01:23,  1.30s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:45<01:19,  1.27s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:46<01:15,  1.21s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:47<01:11,  1.18s/it]\u001b[A\n",
      " 40%|████      | 40/100 [00:48<01:10,  1.17s/it]\u001b[A\n",
      " 41%|████      | 41/100 [00:50<01:08,  1.16s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:51<01:14,  1.28s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:52<01:13,  1.29s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:54<01:14,  1.33s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:55<01:10,  1.27s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:56<01:06,  1.23s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:57<01:01,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:58<00:59,  1.14s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:59<00:55,  1.09s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:00<00:52,  1.06s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:01<00:53,  1.08s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:02<00:52,  1.10s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:04<00:51,  1.10s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:05<00:50,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:06<00:48,  1.07s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:07<00:45,  1.04s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [01:08<00:45,  1.07s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [01:09<00:45,  1.09s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [01:10<00:44,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [01:11<00:44,  1.11s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [01:12<00:41,  1.08s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [01:13<00:41,  1.09s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [01:14<00:40,  1.10s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [01:15<00:38,  1.06s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [01:16<00:37,  1.08s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [01:18<00:37,  1.11s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [01:19<00:38,  1.17s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [01:20<00:40,  1.28s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [01:22<00:38,  1.25s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "## Entrena la red neuronal implementada en la celda anterior y grafica el error\n",
    "mnist_nn = NN(784,26,10)\n",
    "mnist_nn.train(XY_Train,100)\n",
    "mnist_nn.test(XTest,YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prueba el modelo entrenado con los datos de prueba y muestra la métrica de exatitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b974cd7d60ef486a9aa1b50730e3b113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=29999, description='indice', max=59999), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(\n",
    "    indice = (0, len(trainData) - 1)\n",
    ")\n",
    "def muestraImagenEntrenamiento(indice):\n",
    "    muestraImagen(trainData, trainDataLabels, indice)\n",
    "    tensor_X = torch.FloatTensor([x_train_tensor[indice].numpy()])\n",
    "    print(\"PREDICCIÓN:\" + str(mnist_nn.feedForward(tensor_X).argmax(dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
